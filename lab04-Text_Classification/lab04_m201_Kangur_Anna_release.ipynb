{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04. Text Classification\n",
    "\n",
    "\n",
    "This lab is devoted to text classification tasks.\n",
    "- **Part 1 [8 points]** is about very common NLP problem - sentiment analysis.\n",
    "- **Part 2 [7 points]** include tasks on POS tagging and WordEmbeddings.\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "Each task has its value, **15 points** in total. If you use some open-source code please make sure to include the url.\n",
    "\n",
    "#### How to submit\n",
    "\n",
    "- Name your file according to this convention: `lab04_GroupNo_Surname_Name.ipynb`. If you don't have group number, put `nan` instead.\n",
    "- Attach it to an **email** with **topic** `lab04_GroupNo_Surname_Name.ipynb`\n",
    "- Send it to `cosmic.research.ml@yandex.ru`\n",
    "\n",
    "\n",
    "Data can be dowloaded from: https://disk.yandex.ru/d/ixeu6m2KBG80ig\n",
    "\n",
    "The deadline is **2021-11-17 23:00:00 +03:00**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Bag of Words vs. Bag of Popcorn [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is based on [Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition. The goal is to label film reviews as positive or negative. \n",
    "\n",
    "Reviews may look like this:\n",
    "\n",
    "```\n",
    "I dont know why people think this is such a bad movie. Its got a pretty good plot, some good action, and the change of location for Harry does not hurt either. Sure some of its offensive and gratuitous but this is not the only movie like that. Eastwood is in good form as Dirty Harry, and I liked Pat Hingle in this movie as the small town cop. If you liked DIRTY HARRY, then you should see this one, its a lot better than THE DEAD POOL. 4/5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit)  — пакет библиотек и программ для символьной и статистической обработки естественного языка, написанных на языке программирования Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"reviews.tsv\", sep=\"\\t\")\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews[\"review\"]\n",
    "y = reviews[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000,), (5000,), (20000,), (5000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to extract features\n",
    "\n",
    "In this part of the assignment we will apply several methods of feature extraction and comapre them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.1 [0.5 point] - Simple BOW (Bag-of-Words)** \n",
    "\n",
    "In this task we will build a simple bow representation - without any preprocessing. \n",
    "\n",
    "For this purpose we will use [*CountVectorizer*](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) - a method that transforms text dataset into a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer - сonvert a collection of text documents to a matrix of token counts.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try each of these approaches:\n",
    "- fit vectorizer on X_train, apply to X_train, X_test\n",
    "- fit vectorizer on X_train, apply to X_train; fit on X_test, apply to X_test\n",
    "- fit vectorizer on X, apply to X_train, X_test\n",
    "\n",
    "Report output matrix sizes in each case. \n",
    "- What is the difference? \n",
    "- Which of these approaches is the most fair and correct?\n",
    "\n",
    "Use the most fair and correct one to get `X_train_0` and `X_test_0` - they will be needed for further tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tmp = vectorizer.fit_transform(['Hi, hi', \n",
    "                                'Hello, hi',\n",
    "                                'Hi',\n",
    "                                'hello'])\n",
    "tmp.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. fit vectorizer on X_train, apply to X_train, X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 68482) (5000, 68482)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train_0 = count_vectorizer.fit_transform(X_train.to_list())\n",
    "X_test_0  = count_vectorizer.transform(X_test.to_list())\n",
    "print(X_train_0.shape, X_test_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. fit vectorizer on X_train, apply to X_train; fit on X_test, apply to X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 68482) (5000, 38591)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_train_0 = count_vectorizer.fit_transform(X_train.to_list())\n",
    "X_test_0  = count_vectorizer.fit_transform(X_test.to_list())\n",
    "print(X_train_0.shape, X_test_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. fit vectorizer on X, apply to X_train, X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 74849) (5000, 74849)\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_0 = count_vectorizer.fit_transform(X.to_list())\n",
    "X_train_0 = count_vectorizer.transform(X_train.to_list())\n",
    "X_test_0  = count_vectorizer.transform(X_test.to_list())\n",
    "print(X_train_0.shape, X_test_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если честно, не особо понимаю, как происходит обучение с **Sparse matrices**. \n",
    "Она преобразовывается в array как-то динамически? \n",
    "Просто когда попыталась преобразовать в array, то Питон ругается, мол слишком большой массив.\n",
    "\n",
    "Если динамически преобразование не происходит, боюсь выше фигня написана)\n",
    "\n",
    "Особенно во вротом случае. Матрицы X_train_0 and X_test_0 как минимум должны быть одинаковой размерности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посколькуво втором случае получились разные размерности, то этот способ точно не подходит. \n",
    "\n",
    "В третьем случае, как мне кажется, слишком большая размерность.\n",
    "\n",
    "**Думаю, наилучший - первый способ.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.2 [0.5 point] - S___se matrices**\n",
    "\n",
    "What is the data type of `X_train_0` and `X_test_0`? What are those?\n",
    "\n",
    "What differs them from usual np.arrays? Name several types how those special matrices are stored and what they are good for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sparse matrices -  матрица с преимущественно нулевыми элементами.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.dok_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **scipy.sparse** есть семь типов разреженных матриц:\n",
    "1. bsr_matrix: Block Sparse Row matrix\n",
    "2. coo_matrix: формат координат (то есть IJV, формат 3D)\n",
    "3. csc_matrix: сжатый формат столбца (compressed row storage)\n",
    "4. csr_matrix: формат сжатой строки (compressed sparse row)\n",
    "5. lil_matrix: формат списка (List of Lists)\n",
    "6. dok_matrix: словарный формат значений (Dictionary of Keys)\n",
    "7. dia_matrix: диагональный формат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. bsr_matrix: Block Sparse Row matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import bsr_matrix\n",
    "bsr_matrix((3, 4), dtype=np.int8).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array( [0, 0, 1, 2, 2, 2])\n",
    "col = np.array( [0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "bsr_matrix((data, (row, col)), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 2, 3, 4, 5, 7]).repeat(4).reshape(6, 2, 2)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 2, 2],\n",
       "       [1, 1, 0, 0, 2, 2],\n",
       "       [0, 0, 0, 0, 3, 3],\n",
       "       [0, 0, 0, 0, 3, 3],\n",
       "       [4, 4, 5, 5, 7, 7],\n",
       "       [4, 4, 5, 5, 7, 7]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr  = np.array([0, 2, 3, 6])\n",
    "indices = np.array([0, 2, 2, 0, 1, 2])\n",
    "bsr_matrix((data,indices,indptr), shape=(6, 6)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 2, 2, 0, 0],\n",
       "       [0, 0, 2, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 3, 3],\n",
       "       [0, 0, 0, 0, 3, 3]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr  = np.array([0, 1, 2, 3])\n",
    "indices = np.array([0, 1, 2, 0, 0, 0])\n",
    "bsr_matrix((data,indices,indptr), shape=(6, 6)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 2, 2],\n",
       "       [0, 0, 0, 0, 2, 2],\n",
       "       [7, 7, 0, 0, 0, 0],\n",
       "       [7, 7, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr  = np.array([0, 1, 2, 4])\n",
    "indices = np.array([1, 2, 0, 0, 0, 0])\n",
    "bsr_matrix((data,indices,indptr), shape=(6, 6)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. scipy.sparse.coo_matrix - a sparse matrix in COOrdinate format.\n",
    "\n",
    "COO хранит список кортежей (строка, столбец, значение). В идеале записи сортируются сначала по индексу строки, а затем по индексу столбца, чтобы сократить время произвольного доступа. Википедия  site:hrwiki.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "coo_matrix((3, 4), dtype=np.int8).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 0, 9, 0],\n",
       "       [0, 7, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 5]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row  = np.array([0, 3, 1, 0])\n",
    "col  = np.array([0, 3, 1, 2])\n",
    "data = np.array([4, 5, 7, 9])\n",
    "coo_matrix((data, (row, col)), shape=(4, 4)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. scipy.sparse.csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "csc_matrix((3, 4), dtype=np.int8).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 4],\n",
       "       [0, 0, 5],\n",
       "       [2, 3, 6]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array([0, 2, 2, 0, 1, 2])\n",
    "col = np.array([0, 0, 1, 2, 2, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "csc_matrix((data, (row, col)), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 4],\n",
       "       [0, 0, 5],\n",
       "       [2, 3, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = np.array([0, 2, 3, 6])\n",
    "indices = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "csc_matrix((data, indices, indptr), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. scipy.sparse.csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "csr_matrix((3, 4), dtype=np.int8).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "csr_matrix((data, (row, col)), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 2],\n",
       "       [0, 0, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = np.array([0, 2, 3, 6])\n",
    "indices = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 4, 0]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = np.array([0, 1, 2, 0])\n",
    "col = np.array([0, 1, 1, 0])\n",
    "data = np.array([1, 2, 4, 8])\n",
    "csr_matrix((data, (row, col)), shape=(3, 3)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. scipy.sparse.dia_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. dok_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. spmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2760558 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_0.toarray()\n",
    "#ValueError: array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3 [1 points] - Training**\n",
    "\n",
    "Train LogisticRegression and Random forest on this data representations.\n",
    "- Compare training time \n",
    "- Compare Accuracy, precision, recall \n",
    "- Plot ROC Curve and calculate ROC AUC (don't forget to predict_proba) \n",
    "- Plot Precision-Recall curve and calculate f1-score (for example, with `plt.subplots(nrows=1, ncols=2)`)\n",
    "- Print the trickiest missclassified objects. Why they were hard to classify? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time as tm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 338.635 seconds\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "start = time()\n",
    "rf_model.fit(X_train_0, y_train)\n",
    "end = time()\n",
    "\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "rf_pred_train = rf_model.predict(X_train_0)\n",
    "rf_pred_test = rf_model.predict(X_test_0)\n",
    "\n",
    "accuracy_score_rf_train = accuracy_score(y_train, rf_pred_train)\n",
    "accuracy_score_rf_test = accuracy_score(y_test, rf_pred_test)\n",
    "\n",
    "precision_score_rf_train = precision_score(y_train, rf_pred_train)\n",
    "precision_score_rf_test = precision_score(y_test, rf_pred_test)\n",
    "\n",
    "recall_score_rf_train = recall_score(y_train, rf_pred_train)\n",
    "recall_score_rf_test = recall_score(y_test, rf_pred_test)\n",
    "\n",
    "f1_score_rf_train = f1_score(y_train, rf_pred_train)\n",
    "f1_score_rf_test  = f1_score(y_test, rf_pred_test)\n",
    "\n",
    "precision_recall_curve_rf_train = precision_recall_curve(y_train, rf_pred_train)\n",
    "precision_recall_curve_rf_test  = precision_recall_curve(y_test, rf_pred_test)\n",
    "\n",
    "roc_curve_rf_train = roc_curve(y_train, rf_pred_train)\n",
    "roc_curve_rf_test  = roc_curve(y_test, rf_pred_test)\n",
    "\n",
    "roc_auc_score_rf_train = roc_auc_score(y_train, rf_pred_train)\n",
    "roc_auc_score_rf_test  = roc_auc_score(y_test, rf_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 15.927 seconds\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=1e5)\n",
    "\n",
    "start = time()\n",
    "lr_model.fit(X_train_0, y_train)\n",
    "end = time()\n",
    "\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "lr_pred_train = lr_model.predict(X_train_0)\n",
    "lr_pred_test  = lr_model.predict(X_test_0)\n",
    "\n",
    "precision_score_lr_train = precision_score(y_train, lr_pred_train)\n",
    "precision_score_lr_test  = precision_score(y_test,  lr_pred_test)\n",
    "\n",
    "recall_score_lr_train = recall_score(y_train, lr_pred_train)\n",
    "recall_score_lr_test  = recall_score(y_test,  lr_pred_test)\n",
    "\n",
    "f1_score_lr_train = f1_score(y_train, lr_pred_train)\n",
    "f1_score_lr_test  = f1_score(y_test, lr_pred_test)\n",
    "\n",
    "precision_recall_curve_lr_train = precision_recall_curve(y_train, lr_pred_train)\n",
    "precision_recall_curve_lr_test  = precision_recall_curve(y_test, lr_pred_test)\n",
    "\n",
    "roc_curve_lr_train = roc_curve(y_train, lr_pred_train)\n",
    "roc_curve_lr_test  = roc_curve(y_test, lr_pred_test)\n",
    "\n",
    "roc_auc_score_lr_train = roc_auc_score(y_train, lr_pred_train)\n",
    "roc_auc_score_lr_test  = roc_auc_score(y_test, lr_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision_score_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score_test</th>\n",
       "      <td>0.843099</td>\n",
       "      <td>0.875640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score_test</th>\n",
       "      <td>0.874800</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_test</th>\n",
       "      <td>0.858657</td>\n",
       "      <td>0.882761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score_train</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score_test</th>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.881800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       RandomForestClassifier  LogisticRegression\n",
       "precision_score_train                1.000000            0.999200\n",
       "precision_score_test                 0.843099            0.875640\n",
       "recall_score_train                   1.000000            0.998800\n",
       "recall_score_test                    0.874800            0.890000\n",
       "f1_score_train                       1.000000            0.999000\n",
       "f1_score_test                        0.858657            0.882761\n",
       "roc_auc_score_train                  1.000000            0.999000\n",
       "roc_auc_score_test                   0.856000            0.881800"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'RandomForestClassifier':   [precision_score_rf_train, \n",
    "                                  precision_score_rf_test,\n",
    "                                     recall_score_rf_train,\n",
    "                                     recall_score_rf_test,\n",
    "                                         f1_score_rf_train,\n",
    "                                         f1_score_rf_test,\n",
    "                                    roc_auc_score_rf_train, \n",
    "                                    roc_auc_score_rf_test],\n",
    "     'LogisticRegression':       [precision_score_lr_train,  \n",
    "                                  precision_score_lr_test,\n",
    "                                     recall_score_lr_train,\n",
    "                                     recall_score_lr_test,\n",
    "                                         f1_score_lr_train,\n",
    "                                         f1_score_lr_test,\n",
    "                                    roc_auc_score_lr_train,\n",
    "                                    roc_auc_score_lr_test]}\n",
    "pd.DataFrame(data=d, index = ['precision_score_train',\n",
    "                              'precision_score_test',\n",
    "                              'recall_score_train',\n",
    "                              'recall_score_test',\n",
    "                              'f1_score_train',\n",
    "                              'f1_score_test',\n",
    "                              'roc_auc_score_train', \n",
    "                              'roc_auc_score_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_importances = [X_train_importances.append(X_train_0[:,i]) for i in ind_15k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name several types how those special matrices are stored and what they are good for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model gives higher scores? Any ideas why? Please suggest 1-2 reasons.\n",
    "\n",
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LogisticRegression показал лучше результат на тестовой выборке.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не знаю даже почему лес справился хуже. \n",
    "\n",
    "Может быть потому что есть ирония? \"отличный фильм\" может восприниматься как плохой. Но этого же не лишена и линейная регрессия.\n",
    "\n",
    "Может быть деревья плохи именно в таких огромных массивах. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More sophisticated feature prerocessing\n",
    "\n",
    "As we have seen, simple BOW can give us some result - it's time to improve it.\n",
    "\n",
    "**Task 1.4 [1 point] - Frequencies calculation**\n",
    "\n",
    "- Calculate top-20 words in train set and test set. *Are they meaningful?*\n",
    "- Import `stopwords` and print some of them. What are those?\n",
    "- Recalculate top-20 words in each set, but exclude stop words.\n",
    "- Does now top-20 include more useful words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythonworld.ru/moduli/modul-collections.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate top-20 words in train set and test set. Are they meaningful?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15061    A very silly movie, this starts with a soft po...\n",
       "10112    1st watched 8/3/2003 - 2 out of 10(Dir-Brad Sy...\n",
       "24550    This is a really heart-warming family movie. I...\n",
       "2570     Nicole Kidman is a wonderful actress and here ...\n",
       "16053    It's very hard to say just what was going on w...\n",
       "                               ...                        \n",
       "20210    The Three Stooges has always been some of the ...\n",
       "15989    And a made for TV movie too, this movie was go...\n",
       "20873    Back in my days as an usher \\Private Lessons\\\"...\n",
       "10422    I might not be a huge admirer of the original ...\n",
       "21768    This movie was an impressive one. My first exp...\n",
       "Name: review, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top-20 words in train set\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '.join(map(str, X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A very silly movie, this starts with a soft porn sequence, ventures into farcelike comedy in the art'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Whitespace = WhitespaceTokenizer().tokenize(s)\n",
    "Counter_Whitespace = Counter(Whitespace)\n",
    "top_Whitespace = [(l,k) for k,l in sorted([(j,i) for i,j in Counter_Whitespace.items()], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordPunct = WordPunctTokenizer().tokenize(s)\n",
    "Counter_WordPunct = Counter(WordPunct)\n",
    "top_WordPunct = [(l,k) for k,l in sorted([(j,i) for i,j in Counter_WordPunct.items()], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreebankWord = TreebankWordTokenizer().tokenize(s)\n",
    "Counter_TreebankWord = Counter(TreebankWord)\n",
    "top_TreebankWord = [(l,k) for k,l in sorted([(j,i) for i,j in Counter_TreebankWord.items()], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_Whitespace\t\t\ttop_WordPunct\t\t\ttop_TreebankWord\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('the', 230191)\t\t\t('the', 232718)\t\t\t('the', 231895)\n",
      "('a', 124236)\t\t\t(',', 210946)\t\t\t(',', 221238)\n",
      "('and', 122525)\t\t\t('.', 180270)\t\t\t('and', 125458)\n",
      "('of', 114632)\t\t\t('and', 126065)\t\t\t('a', 125014)\n",
      "('to', 106231)\t\t\t('a', 125408)\t\t\t('of', 115057)\n",
      "('is', 82852)\t\t\t('of', 115592)\t\t\t('to', 106660)\n",
      "('in', 68303)\t\t\t('to', 107393)\t\t\t('is', 86915)\n",
      "('I', 52896)\t\t\t(\"'\", 104320)\t\t\t('/', 81829)\n",
      "('that', 51864)\t\t\t('is', 85332)\t\t\t('>', 81789)\n",
      "('this', 45937)\t\t\t('br', 81648)\t\t\t('<', 81742)\n",
      "('it', 43691)\t\t\t('in', 70114)\t\t\t('br', 81648)\n",
      "('/><br', 40824)\t\t\t('I', 65898)\t\t\t('in', 69149)\n",
      "('was', 37452)\t\t\t('it', 62493)\t\t\t('I', 65008)\n",
      "('as', 33868)\t\t\t('that', 56535)\t\t\t('it', 56833)\n",
      "('with', 33567)\t\t\t('s', 50464)\t\t\t('that', 55557)\n",
      "('for', 32891)\t\t\t('this', 48839)\t\t\t(\"''\", 52892)\n",
      "('The', 27102)\t\t\t('-', 44759)\t\t\t(\"'s\", 49338)\n",
      "('but', 27011)\t\t\t('/><', 40824)\t\t\t('this', 47639)\n",
      "('on', 24827)\t\t\t('/>', 39157)\t\t\t('was', 39719)\n",
      "('movie', 24625)\t\t\t('was', 38383)\t\t\t('as', 34629)\n"
     ]
    }
   ],
   "source": [
    "print('top_Whitespace','top_WordPunct','top_TreebankWord', sep = '\\t\\t\\t')\n",
    "print('-'*100)\n",
    "for i in range(20): \n",
    "    print(top_Whitespace[i], top_WordPunct[i], top_TreebankWord[i], sep = '\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слова не значимы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythonspot.com/nltk-stop-words/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Пользователь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "stopWords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stopWorsd(Words,stopWords):\n",
    "    n = len(Words)\n",
    "    new_Words = []\n",
    "    for i in range(n):\n",
    "        if not(Words[i][0] in stopWords):\n",
    "            new_Words.append(Words[i])\n",
    "    return new_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_Whitespace\t\t\ttop_WordPunct\t\t\ttop_TreebankWord\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('I', 52896)\t\t\t(',', 210946)\t\t\t(',', 221238)\n",
      "('/><br', 40824)\t\t\t('.', 180270)\t\t\t('/', 81829)\n",
      "('The', 27102)\t\t\t(\"'\", 104320)\t\t\t('>', 81789)\n",
      "('movie', 24625)\t\t\t('br', 81648)\t\t\t('<', 81742)\n",
      "('film', 22030)\t\t\t('I', 65898)\t\t\t('br', 81648)\n",
      "('one', 16664)\t\t\t('-', 44759)\t\t\t('I', 65008)\n",
      "('like', 14536)\t\t\t('/><', 40824)\t\t\t(\"''\", 52892)\n",
      "('This', 9886)\t\t\t('/>', 39157)\t\t\t(\"'s\", 49338)\n",
      "('would', 9528)\t\t\t('The', 36086)\t\t\t('The', 34492)\n",
      "('good', 9043)\t\t\t('movie', 34953)\t\t\t('movie', 29399)\n",
      "('It', 8759)\t\t\t('film', 31956)\t\t\t(')', 29058)\n",
      "('really', 8691)\t\t\t('\\\\\"', 31496)\t\t\t('(', 28452)\n",
      "('even', 8569)\t\t\t('.<', 29402)\t\t\t('film', 27091)\n",
      "('see', 8190)\t\t\t('(', 27203)\t\t\t(\"n't\", 26125)\n",
      "('-', 7494)\t\t\t('one', 19670)\t\t\t('\\\\', 20220)\n",
      "('get', 6977)\t\t\t('like', 15645)\t\t\t('!', 19962)\n",
      "('much', 6888)\t\t\t('It', 14736)\t\t\t('one', 18004)\n",
      "('story', 6838)\t\t\t(')', 13515)\t\t\t('like', 15097)\n",
      "('time', 6236)\t\t\t('This', 12012)\t\t\t('It', 14448)\n",
      "('make', 5987)\t\t\t('good', 11492)\t\t\t('?', 12847)\n"
     ]
    }
   ],
   "source": [
    "top_Whitespace_del_stopWorsd   = del_stopWorsd(top_Whitespace,stopWords)\n",
    "top_WordPunct_del_stopWorsd    = del_stopWorsd(top_WordPunct, stopWords)\n",
    "top_TreebankWord_del_stopWorsd = del_stopWorsd(top_TreebankWord,stopWords)\n",
    "\n",
    "print('top_Whitespace','top_WordPunct','top_TreebankWord', sep = '\\t\\t\\t')\n",
    "print('-'*100)\n",
    "for i in range(20): \n",
    "    print(top_Whitespace_del_stopWorsd[i], \n",
    "          top_WordPunct_del_stopWorsd[i], \n",
    "          top_TreebankWord_del_stopWorsd[i], \n",
    "          sep = '\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все равно очень много \"мусора\": **'/><br'**, **'br'**, **','**, **'>'**, **'\\\\'** и пр."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'br' in stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopSign = ['.', ',', '<', '>', '\"', '\\\\', '|', '/', ';', ':', '-', '\\\\', \"'\",\n",
    "            '/><', '(', ')', '/><br','\\\\\"','.<', '-','/>','br','...','!', '&', '?', \"''\",\n",
    "           '/>The', '<br', '/>I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_Whitespace\t\t\ttop_WordPunct\t\t\ttop_TreebankWord\n",
      "----------------------------------------------------------------------------------------------------\n",
      "('I', 52896)\t\t\t('I', 65898)\t\t\t('I', 65008)\n",
      "('The', 27102)\t\t\t('The', 36086)\t\t\t(\"'s\", 49338)\n",
      "('movie', 24625)\t\t\t('movie', 34953)\t\t\t('The', 34492)\n",
      "('film', 22030)\t\t\t('film', 31956)\t\t\t('movie', 29399)\n",
      "('one', 16664)\t\t\t('one', 19670)\t\t\t('film', 27091)\n",
      "('like', 14536)\t\t\t('like', 15645)\t\t\t(\"n't\", 26125)\n",
      "('This', 9886)\t\t\t('It', 14736)\t\t\t('one', 18004)\n",
      "('would', 9528)\t\t\t('This', 12012)\t\t\t('like', 15097)\n",
      "('good', 9043)\t\t\t('good', 11492)\t\t\t('It', 14448)\n",
      "('It', 8759)\t\t\t('time', 9922)\t\t\t('This', 11832)\n",
      "('really', 8691)\t\t\t('would', 9834)\t\t\t('would', 10538)\n",
      "('even', 8569)\t\t\t('story', 9267)\t\t\t('good', 10154)\n",
      "('see', 8190)\t\t\t('really', 9108)\t\t\t('really', 8956)\n",
      "('get', 6977)\t\t\t('see', 8963)\t\t\t('even', 8848)\n",
      "('much', 6888)\t\t\t('even', 8896)\t\t\t('see', 8568)\n",
      "('story', 6838)\t\t\t('much', 7635)\t\t\t('story', 8060)\n",
      "('time', 6236)\t\t\t('well', 7301)\t\t\t('time', 7700)\n",
      "('make', 5987)\t\t\t('get', 7222)\t\t\t('could', 7290)\n",
      "('also', 5983)\t\t\t('people', 7096)\t\t\t('much', 7196)\n",
      "('could', 5948)\t\t\t('bad', 7061)\t\t\t('get', 7083)\n"
     ]
    }
   ],
   "source": [
    "top_Whitespace_del   = del_stopWorsd(top_Whitespace_del_stopWorsd,stopSign)\n",
    "top_WordPunct_del  = del_stopWorsd(top_WordPunct_del_stopWorsd,stopSign)\n",
    "top_TreebankWord_del = del_stopWorsd(top_TreebankWord_del_stopWorsd,stopSign)\n",
    "\n",
    "print('top_Whitespace','top_WordPunct','top_TreebankWord', sep = '\\t\\t\\t')\n",
    "print('-'*100)\n",
    "for i in range(20): \n",
    "    print(top_Whitespace_del[i], \n",
    "          top_WordPunct_del[i], \n",
    "          top_TreebankWord_del[i], \n",
    "          sep = '\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whitespace** показывает больше полезных слов, однако, убрав символы, все равно видно, что три свособа дают ± одинаковый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.5 [1 point] - Word Freqs by class**\n",
    "\n",
    "How do you think, will top100 tokens for positive and negative classes be different? Use data to prove your point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_class = X[y==1] \n",
    "negative_class = X[y==0] \n",
    "positive_class.shape[0] + negative_class.shape[0] == X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_positive = ' '.join(map(str, positive_class))\n",
    "s_negative = ' '.join(map(str, negative_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Whitespace = WhitespaceTokenizer().tokenize(s_positive)\n",
    "Counter_Whitespace = Counter(Whitespace)\n",
    "top_positive = [(l,k) for k,l in sorted([(j,i) for i,j in Counter_Whitespace.items()], reverse=True)]\n",
    "\n",
    "Whitespace = WhitespaceTokenizer().tokenize(s_negative)\n",
    "Counter_Whitespace = Counter(Whitespace)\n",
    "top_negative = [(l,k) for k,l in sorted([(j,i) for i,j in Counter_Whitespace.items()], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopSign = ['.', ',', '<', '>', '\"', '\\\\', '|', '/', ';', ':', '-', '\\\\', \"'\",\n",
    "            '/><', '(', ')', '/><br','\\\\\"','.<', '-','/>','br','...','!', '&', '?', \"''\",\n",
    "           '/>The', '<br', '/>I', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive = del_stopWorsd(top_positive,stopWords)\n",
    "top_positive = del_stopWorsd(top_positive,stopSign) \n",
    "#top_positive[:20]\n",
    "\n",
    "top_negative = del_stopWorsd(top_negative,stopWords)\n",
    "top_negative = del_stopWorsd(top_negative,stopSign) \n",
    "#top_negative[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('top_positive','top_negative', sep = '\\t\\t\\t')\n",
    "#print('-'*100)\n",
    "#for i in range(100): \n",
    "#    print(top_positive[i], top_negative[i], sep = '\\t\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "± одинаковый результат ('I', 'film', 'see' ...)\n",
    "\n",
    "В top_positive чаще встречаются слова с позитивным окрасом: ('like', 7978), ('good', 5793), ('great', 5100), ('well', 3606), ('best', 3387), ('love', 3325), ('better', 1879)...\n",
    "\n",
    "Однако в top_negative они тоже встречаются, причем слова ('like', 10155), ('good', 5642), ('better', 2527) даже чаще. \n",
    "Это увеличит ошибку при обучении. \n",
    "Но ('great', 2091), ('love', 1648), ('best', 1588) на порядок меньше. \n",
    "Чаще встречаются слова с негативным окрасом ('bad', 5096), ('never', 3010), ('least', 1775), но их как будто тоже не особо много."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.6 [2 points] - Reducing dimensionality**\n",
    "\n",
    "The goal is to reduce number of features to 15000.\n",
    "\n",
    "Implement the following methods of dimensinality reduction:\n",
    "1. Use CountVectorizer, but leave only 15k most frequent tokens\n",
    "2. Use HashingVectorizer with 15k features\n",
    "3. Use 15k most important features from perspective of previously trained RandomForest\n",
    "\n",
    "*Hints:*\n",
    "- in 1 and 2 you don't have to apply nltk.corpus.stopwords, vectorizers have `stopwords` parameter\n",
    "- in 1 look for `vocabulary` parameter\n",
    "- in 3... remember `lab02`? You may use `X_train_0` and `X_test_0` as input matrices\n",
    "\n",
    "Train LogisticRegression and RandomForest on each dataset and compare ROC AUC scores of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146099"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_TreebankWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = top_TreebankWord\n",
    "top = del_stopWorsd(top,stopWords)\n",
    "top = del_stopWorsd(top,stopSign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_15k = top_TreebankWord[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_top_15k = [w[0] for w in top_15k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vectorizer = CountVectorizer()\n",
    "#count_vectorizer.fit(list_top_15k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Use CountVectorizer, but leave only 15k most frequent tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=15000, stop_words='english')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 15000)\n",
    "count_vectorizer.fit(X_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv = count_vectorizer.transform(X_train.to_list())\n",
    "X_test_cv  = count_vectorizer.transform(X_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 37.891 seconds\n"
     ]
    }
   ],
   "source": [
    "rf_cv = RandomForestClassifier()\n",
    "\n",
    "start = time()\n",
    "rf_cv.fit(X_train_cv, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "rf_cv_pred_train = rf_cv.predict(X_train_cv)\n",
    "rf_cv_pred_test = rf_cv.predict(X_test_cv)\n",
    "\n",
    "rf_cv_score_train = roc_auc_score(y_train, rf_cv_pred_train)\n",
    "rf_cv_score_test  = roc_auc_score(y_test,  rf_cv_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8514)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv_score_train, rf_cv_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 0.843 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr_cv = LogisticRegression()\n",
    "\n",
    "start = time()\n",
    "lr_cv.fit(X_train_cv, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "lr_cv_pred_train = lr_cv.predict(X_train_cv)\n",
    "lr_cv_pred_test  = lr_cv.predict(X_test_cv)\n",
    "\n",
    "lr_cv_score_train = roc_auc_score(y_train, lr_cv_pred_train)\n",
    "lr_cv_score_test  = roc_auc_score(y_test,  lr_cv_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9959, 0.8738)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_score_train, lr_cv_score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Use HashingVectorizer with 15k features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(stop_words = 'english', n_features=1500)\n",
    "hashing_vectorizer = vectorizer.fit(X_train.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hv = hashing_vectorizer.transform(X_train.to_list())\n",
    "X_test_hv  = hashing_vectorizer.transform(X_test.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 56.483 seconds\n"
     ]
    }
   ],
   "source": [
    "rf_hv = RandomForestClassifier()\n",
    "\n",
    "start = time()\n",
    "rf_hv.fit(X_train_hv, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "rf_hv_pred_train = rf_hv.predict(X_train_hv)\n",
    "rf_hv_pred_test = rf_hv.predict(X_test_hv)\n",
    "\n",
    "rf_hv_score_train = roc_auc_score(y_train, rf_hv_pred_train)\n",
    "rf_hv_score_test  = roc_auc_score(y_test,  rf_hv_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8022000000000001)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_hv_score_train, rf_hv_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 0.523 seconds\n"
     ]
    }
   ],
   "source": [
    "lr_hv = LogisticRegression()\n",
    "\n",
    "start = time()\n",
    "lr_hv.fit(X_train_hv, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "lr_hv_pred_train = lr_hv.predict(X_train_hv)\n",
    "lr_hv_pred_test  = lr_hv.predict(X_test_hv)\n",
    "\n",
    "lr_hv_score_train = roc_auc_score(y_train, lr_hv_pred_train)\n",
    "lr_hv_score_test  = roc_auc_score(y_test,  lr_hv_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9959, 0.8738)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cv_score_train, lr_cv_score_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Use 15k most important features from perspective of previously trained RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 74849), (5000, 74849))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.shape, X_test_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train_0, y_train)\n",
    "#rf_pred_train = rf_model.predict(X_train_0)\n",
    "#rf_pred_test = rf_model.predict(X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importances = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rf_feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'rf_feature_importances': rf_feature_importances}\n",
    "df = pd.DataFrame(data=d) \n",
    "df = df.sort_values(by=['rf_feature_importances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(rf_feature_importances)-1\n",
    "df_15k = df[n-15000:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_15k = df_15k.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 74849)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_importances = X_train_0[:,ind_15k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_importances = X_test_0[:,ind_15k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 46.225 seconds\n"
     ]
    }
   ],
   "source": [
    "rf_rf = RandomForestClassifier()\n",
    "\n",
    "start = time()\n",
    "rf_rf.fit(X_train_importances, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "rf_rf_pred_train = rf_rf.predict(X_train_importances)\n",
    "rf_rf_pred_test  = rf_rf.predict(X_test_importances)\n",
    "\n",
    "rf_rf_score_train = roc_auc_score(y_train, rf_rf_pred_train)\n",
    "rf_rf_score_test  = roc_auc_score(y_test,  rf_rf_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 8.736 seconds\n"
     ]
    }
   ],
   "source": [
    "lr_rf = LogisticRegression(max_iter=1e5)\n",
    "\n",
    "start = time()\n",
    "lr_rf.fit(X_train_importances, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rf_pred_train = lr_rf.predict(X_train_importances)\n",
    "lr_rf_pred_test  = lr_rf.predict(X_test_importances)\n",
    "\n",
    "lr_rf_score_train = roc_auc_score(y_train, lr_rf_pred_train)\n",
    "lr_rf_score_test  = roc_auc_score(y_test,  lr_rf_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountVectorizer</th>\n",
       "      <th>HashingVectorizer</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf_train</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_test</th>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.80220</td>\n",
       "      <td>0.84060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_train</th>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.84725</td>\n",
       "      <td>0.99725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_test</th>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.82880</td>\n",
       "      <td>0.87380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CountVectorizer  HashingVectorizer  RandomForestClassifier\n",
       "rf_train           1.0000            1.00000                 1.00000\n",
       "rf_test            0.8514            0.80220                 0.84060\n",
       "lr_train           0.9959            0.84725                 0.99725\n",
       "lr_test            0.8738            0.82880                 0.87380"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'CountVectorizer':       [rf_cv_score_train, rf_cv_score_test,lr_cv_score_train, lr_cv_score_test],\n",
    "     'HashingVectorizer':     [rf_hv_score_train, rf_hv_score_test,lr_hv_score_train, lr_hv_score_test],\n",
    "     'RandomForestClassifier':[rf_rf_score_train, rf_rf_score_test,lr_rf_score_train, lr_rf_score_test]}\n",
    "\n",
    "pd.DataFrame(data=d, index =  ['rf_train','rf_test','lr_train','lr_test' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.7 [2 points] - Token Normalization**\n",
    "\n",
    "Choose the best working method from previous task. Try improve it by applying a token normalization technique.\n",
    "\n",
    "You may use one of **normalizers imported below**, but feel free to experiment.\n",
    "\n",
    "Do the following:\n",
    "- Apply normalizer to X_train, X_test\n",
    "- Build BOW with CountVectorizer + stopwords. What are the shapes of train and test matrices now?\n",
    "- Reduce dimensionality with the best method from Task 2.6. You may try all of them\n",
    "- Train LR/RF to examine whether ROC AUC or Accuracy was improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лемматизация** и **стемминг** — это процессы преобразования слова в его базовую форму. \n",
    "\n",
    "Разница между **стемминг** (**stemming**) и **лемматизацией** заключается в том, что лемматизация учитывает контекст и преобразует слово в его значимую базовую форму, тогда как стемминг просто удаляет последние несколько символов, что часто приводит к неверному значению и орфографическим ошибкам.\n",
    "\n",
    "Например, лемматизация правильно определила бы базовую форму **«caring»** и **«care»**, в то время как стемминг отрезал бы «ing» и преобразовал ее в **car**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Пользователь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caring\n",
      "care\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"caring\"))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "print(stemmer.stem(\"caring\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lemmatizer(X):\n",
    "    Y = []\n",
    "    for i in X:\n",
    "        word_list = TreebankWordTokenizer().tokenize(i)\n",
    "        word_list = del_stopWorsd(word_list,stopWords)\n",
    "        word_list = del_stopWorsd(word_list,stopSign)\n",
    "        lemm_srt  = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "        Y.append(lemm_srt)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_Lemmatizer = Lemmatizer(X_train[:2])\n",
    "#X_train_Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Lemmatizer = Lemmatizer(X_train)\n",
    "X_test_Lemmatizer = Lemmatizer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemmer(X):\n",
    "    Y = []\n",
    "    for i in X:\n",
    "        word_list = TreebankWordTokenizer().tokenize(i)\n",
    "        word_list = del_stopWorsd(word_list,stopWords)\n",
    "        word_list = del_stopWorsd(word_list,stopSign)\n",
    "        lemm_srt  = ' '.join([stemmer.stem(w) for w in word_list])\n",
    "        Y.append(lemm_srt)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Stemmer = Stemmer(X_train)\n",
    "X_test_Stemmer = Stemmer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_Lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_Lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=15000, stop_words='english')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 15000)\n",
    "count_vectorizer.fit(X_train_Lemmatizer)\n",
    "# MemoryError: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_vectorizer.transform(X_train_Lemmatizer)\n",
    "X_test  = count_vectorizer.transform(X_test_Lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 33.605 seconds\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "start = time()\n",
    "rf.fit(X_train, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "rf_pred_train = rf.predict(X_train)\n",
    "rf_pred_test = rf.predict(X_test)\n",
    "\n",
    "rf_roc_auc_train_l = roc_auc_score(y_train, rf_pred_train)\n",
    "rf_roc_auc_test_l  = roc_auc_score(y_test,  rf_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 0.695 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "start = time()\n",
    "lr.fit(X_train, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "lr_pred_train = lr.predict(X_train)\n",
    "lr_pred_test  = lr.predict(X_test)\n",
    "\n",
    "lr_roc_auc_train_l = roc_auc_score(y_train, lr_pred_train)\n",
    "lr_roc_auc_test_l  = roc_auc_score(y_test,  lr_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_features=15000, stop_words='english')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 15000)\n",
    "count_vectorizer.fit(X_train_Stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_vectorizer.transform(X_train_Stemmer)\n",
    "X_test = count_vectorizer.transform(X_test_Stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 33.052 seconds\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "start = time()\n",
    "rf.fit(X_train, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "rf_pred_train = rf.predict(X_train)\n",
    "rf_pred_test = rf.predict(X_test)\n",
    "\n",
    "rf_roc_auc_train_s = roc_auc_score(y_train, rf_pred_train)\n",
    "rf_roc_auc_test_s  = roc_auc_score(y_test,  rf_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 0.689 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "start = time()\n",
    "lr.fit(X_train, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))\n",
    "\n",
    "lr_pred_train = lr.predict(X_train)\n",
    "lr_pred_test  = lr.predict(X_test)\n",
    "\n",
    "lr_roc_auc_train_s = roc_auc_score(y_train, lr_pred_train)\n",
    "lr_roc_auc_test_s  = roc_auc_score(y_test,  lr_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lemmatizer train</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatizer test</th>\n",
       "      <td>0.82960</td>\n",
       "      <td>0.82460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stemmer train</th>\n",
       "      <td>0.98235</td>\n",
       "      <td>0.97995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stemmer test</th>\n",
       "      <td>0.85000</td>\n",
       "      <td>0.84960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  LogisticRegression  RandomForestClassifier\n",
       "Lemmatizer train             1.00000                 1.00000\n",
       "Lemmatizer test              0.82960                 0.82460\n",
       "Stemmer train                0.98235                 0.97995\n",
       "Stemmer test                 0.85000                 0.84960"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'LogisticRegression':[rf_roc_auc_train_l,rf_roc_auc_test_l,lr_roc_auc_train_l,lr_roc_auc_test_l],\n",
    "     'RandomForestClassifier':[rf_roc_auc_train_s,rf_roc_auc_test_s,lr_roc_auc_train_s,lr_roc_auc_test_s]}\n",
    "pd.DataFrame(data=d, index =  ['Lemmatizer train','Lemmatizer test','Stemmer train','Stemmer test' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При Lemmatizer и Stemmer, LogisticRegression показывает лучший результат, чем RandomForestClassifier.\n",
    "\n",
    "При этом, используя Stemmer, и LogisticRegression, и RandomForestClassifier предстказывают лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Word Embeddings [7 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of pretrained word embedding models. We suggest using `glove-wiki-gigaword-100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fasttext-wiki-news-subwords-300',\n",
       " 'conceptnet-numberbatch-17-06-300',\n",
       " 'word2vec-ruscorpora-300',\n",
       " 'word2vec-google-news-300',\n",
       " 'glove-wiki-gigaword-50',\n",
       " 'glove-wiki-gigaword-100',\n",
       " 'glove-wiki-gigaword-200',\n",
       " 'glove-wiki-gigaword-300',\n",
       " 'glove-twitter-25',\n",
       " 'glove-twitter-50',\n",
       " 'glove-twitter-100',\n",
       " 'glove-twitter-200',\n",
       " '__testing_word2vec-matrix-synopsis']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_embeddings = gensim.downloader.load(\"glove-wiki-gigaword-100\")\n",
    "#---------------------------------------------------------------------------\n",
    "#MemoryError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MemoryError**: Unable to allocate 153. MiB for an array with shape (400000, 100) and data type float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.1 [2 point] - WordEmbeddings Geometry**\n",
    "\n",
    "As you probably know, vector space of word embeddings has non-trivial geometry: some word relations (like country-capital or single-plural) cab be represented by vectors, like: **(king - man) + woman = queen**\n",
    "\n",
    "<img src=\"https://linkme.ufanet.ru/images/5687a2011b49eb2413912f1c7d0fb0bd.png\" width=600px>\n",
    "\n",
    "Check this statement on words from the above picture with `word_embeddings.most_similar` function. Pay attention to `positive` and `negative` params.\n",
    "\n",
    "Provide **several** examples, make sure to present different relations: some for nouns, some for verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "#queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nouns\n",
    "#trained_model.most_similar(positive=['', ''], negative=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verbs\n",
    "#trained_model.most_similar(positive=['', ''], negative=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.2 [2 point] - POS analysis**\n",
    "\n",
    "Use POS tagger to calculate most common POS in the dataset. \n",
    "Here you may read about nltk-taggers: [link](https://www.inf.ed.ac.uk/teaching/courses/icl/nltk/tagging.pdf)\n",
    "\n",
    "- If you were to design POS-related weights, how would you do it? \n",
    "- What POS would get the higher weight? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part-of-Speech Tagging (Часть речи)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теги частей речи делят слова на категории в зависимости от того, как они могут быть объединены в предложения. Например, артикли могут сочетаться с существительными, но не с глаголами. \n",
    "\n",
    "Теги части речи также предоставляют информацию о семантическом содержании слова. Например, существительные обычно выражают «вещи», а предлоги выражают отношения между «вещами».\n",
    "\n",
    "В большинстве наборов тегов частей речи используются одни и те же основные категории, такие как «существительное», «глагол», «прилагательное» и «предлог». \n",
    "\n",
    "Однако наборы тегов отличаются как тем, насколько точно они делят слова на категории; и в том, как определить их категории. Например, «is» может быть помечен как глагол в одном наборе тегов; но как форма «быть» в другом наборе тегов.\n",
    "\n",
    "Такое разнообразие в наборах тегов разумно, поскольку теги частей речи используются по-разному для разных задач. В этом руководстве мы будем использовать набор тегов, указанный в Таблице 1. Этот набор тегов является упрощением широко используемого набора тегов Brown Corpus. Полный набор тегов Brown Corpus состоит из 87 основных тегов. Дополнительные сведения о наборах тегов см. в разделе «Основы статистической обработки естественного языка» (Manning & Schutze), стр. 139–145."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AT Article\n",
    "* NN Noun\n",
    "* VB Verb\n",
    "* JJ Adjective\n",
    "* IN Preposition\n",
    "* CD Number\n",
    "* END Sentence-ending punctuation\n",
    "\n",
    "https://www.nltk.org/book/ch05.html\n",
    "\n",
    "https://www.guru99.com/pos-tagging-chunking-nltk.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Пользователь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Token: [('learn', 'JJ'), ('php', 'NN'), ('from', 'IN'), ('guru99', 'NN'), ('and', 'CC'), ('make', 'VB'), ('study', 'NN'), ('easy', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "text =\"learn php from guru99 and make study easy\".split()\n",
    "tokens_tag = pos_tag(text)\n",
    "print(\"After Token:\", tokens_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_Lemmatizer = Lemmatizer(X)\n",
    "#len(X_Lemmatizer)\n",
    "#X_Lemmatizer[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 977965, 218833, 506548, 657833, 60646, 0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = X.shape[0]\n",
    "AT, NN, VB, JJ, IN, CD, END = 0, 0, 0, 0, 0, 0, 0\n",
    "for j in range(m):\n",
    "    tokens_tag = pos_tag(X[j].split())\n",
    "    n = len(tokens_tag)\n",
    "    for i in range(n):\n",
    "        AT += int(tokens_tag[i][1] == 'AT')\n",
    "        NN += int(tokens_tag[i][1] == 'NN')\n",
    "        VB += int(tokens_tag[i][1] == 'VB')\n",
    "        JJ += int(tokens_tag[i][1] == 'JJ')\n",
    "        IN += int(tokens_tag[i][1] == 'IN')\n",
    "        CD += int(tokens_tag[i][1] == 'CD')\n",
    "        END += int(tokens_tag[i][1] == 'END')\n",
    "AT, NN, VB, JJ, IN, CD, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AT': 0,\n",
       " 'NN': 977965,\n",
       " 'VB': 218833,\n",
       " 'JJ': 506548,\n",
       " 'IN': 657833,\n",
       " 'CD': 60646,\n",
       " 'END': 0}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'AT':AT, 'NN':NN, 'VB':VB, 'JJ':JJ, 'IN':IN, 'CD':CD, 'END':END}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 место - **JJ Adjective**: хороший/плохой, глубокий, слабый, отличный, ужасный, милый, мерзкий, стращный\n",
    "\n",
    "2 место - **VB Verb**: понравился, я смеялся/плакал, заставил задуматься, держал в напряжении\n",
    "\n",
    "далее веса значительно слабее, потому что по ним сложно определить отношение к фильму\n",
    "\n",
    "3 место - **NN Noun**: война, юмор, легкость, расслабление/напряжение, страх/радость\n",
    "\n",
    "4 место - **END Sentence-ending punctuation**: !, ?!, ..., !!!11\n",
    "\n",
    "5 место - **CD Number**: 10 из 10, тясячу раз посмотрел, фильм на один раз\n",
    "\n",
    "Минимальные веса\n",
    "\n",
    "4 место - **IN Preposition**, **AT Article** - очень мало о чем говорят"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.3 [3 points] - WordEmbeddings**\n",
    "\n",
    "Use dense vector representations to construct vector-representation of each review, then train a model (LR or RF).\n",
    "\n",
    "Compare results of the new model to results of the models above.\n",
    "**Important**\n",
    "- If you just sum embeddings of each token to get an embedding of the whole review, the cost of the task is **[2 points]**\n",
    "- For **[3 points]** you have to use either TF-IDF weight or weights that you designed from POS tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "преобразование набора необработанных документов в матрицу функций TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = ['This is the first document.',\n",
    "        'This document is the second document.',\n",
    "        'And this is the third one.',\n",
    "        'Is this the first document?']\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "\n",
    "**Term Frequency (TF)-Inverse Document Frequency (IDF)**\n",
    "\n",
    "**1. Частота слова (Term Frequency)** - вероятность найти какое-то слово **wi** в документе **dj**:\n",
    "\n",
    "n - количество раз, которое wi встречается в dj\n",
    "\n",
    "m - общее число слов в dj\n",
    "\n",
    "**TF(wi,dj) = m / n**\n",
    "\n",
    "**2. Обратная частота документа (Inverse Document Frequency)**\n",
    "\n",
    "В логике IDF, если слово встречается во всех документах, оно не очень полезно. Так определяется, насколько уникально слово во всем корпусе.\n",
    "\n",
    "**IDF(wi,Dc) = log(N/ni)** \n",
    "\n",
    "Dc - все документы в корпусе,\n",
    "\n",
    "N = Общее число документов,\n",
    "\n",
    "ni = документы, которые содержат слово (wi).\n",
    "\n",
    "**3. TF-IDF — умножение значений TF и IDF** \n",
    "\n",
    "**TF(wi, dj) * IDF(wi, Dc)**\n",
    "\n",
    "Больший вес получат слова, которые встречаются в документе чаще, чем во всем остальном корпусе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"reviews.tsv\", sep=\"\\t\")\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = reviews[\"review\"]\n",
    "y = reviews[\"sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Пользователь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Пользователь\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopWords = stopwords.words('english')\n",
    "\n",
    "stopSign = ['.', ',', '<', '>', '\"', '\\\\', '|', '/', ';', ':', '-', '\\\\', \"'\",\n",
    "            '/><', '(', ')', '/><br','\\\\\"','.<', '-','/>','br','...','!', '&', '?', \"''\",\n",
    "           '/>The', '<br', '/>I']\n",
    "\n",
    "def del_stopWorsd(Words,stopWords):\n",
    "    n = len(Words)\n",
    "    new_Words = []\n",
    "    for i in range(n):\n",
    "        if not(Words[i][0] in stopWords):\n",
    "            new_Words.append(Words[i])\n",
    "    return new_Words\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def Lemmatizer(X):\n",
    "    Y = []\n",
    "    for i in X:\n",
    "        word_list = TreebankWordTokenizer().tokenize(i)\n",
    "        word_list = del_stopWorsd(word_list,stopWords)\n",
    "        word_list = del_stopWorsd(word_list,stopSign)\n",
    "        lemm_srt  = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "        Y.append(lemm_srt)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Lemmatizer(X_train)\n",
    "X_test = Lemmatizer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_TV_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TV_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 208.532 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "rf.fit(X_TV_train, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8362)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_TV_train, y_train), rf.score(X_TV_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead time: 2.560 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "lr.fit(X_TV_train, y_train)\n",
    "end = time()\n",
    "print('lead time: {:.3f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92045, 0.8752)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_TV_train, y_train), lr.score(X_TV_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://datastart.ru/blog/read/plavnoe-vvedenie-v-natural-language-processing-nlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
